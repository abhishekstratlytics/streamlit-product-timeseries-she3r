{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f130b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import datetime\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d39f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_multi = pd.read_csv('Sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ff018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7d4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for stationarity and returns the order of differencing required\n",
    "def return_stationary(sales_orignal):\n",
    "    ctr=0\n",
    "    if adfuller(sales_orignal)[1]>0.05:\n",
    "        while(ctr<=3):\n",
    "            ctr+=1\n",
    "            sales_orignal = sales_orignal - sales_orignal.shift(1)\n",
    "            sales_orignal.dropna(inplace=True)\n",
    "            if adfuller(sales_orignal)[1]<=0.05:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777b7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training and testing Datasets required for time series modelling\n",
    "def train_test_data_prep_ts(data,training_periods):\n",
    "    train_data = data[:training_periods]\n",
    "    test_data = data[training_periods:]\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba9b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated the input data required for forcasting values of test period using regression models\n",
    "def train_test_data_prep_reg(data,periods_of_forecast,training_periods):\n",
    "    test_periods=len(data)-training_periods\n",
    "    sales = data.copy(deep=True)\n",
    "    d = sales.columns[0]\n",
    "    sales['Lag_p']=sales[d].shift(periods_of_forecast) # Lag for p periods\n",
    "    sales['Lag_p1']=sales[d].shift(periods_of_forecast+1) # Lag for p+1 periods\n",
    "    sales=sales.dropna()\n",
    "    #Creating values for model metrics calculation\n",
    "    x1_v,x2_v,y=sales['Lag_p'],sales['Lag_p1'],sales[d] #Storing values of lags(independent features) and actual sales(dependent feature) in series\n",
    "    x1_v,x2_v,y=np.array(x1_v),np.array(x2_v),np.array(y) #Converting the series in array\n",
    "    x1_v,x2_v,y=x1_v.reshape(-1,1),x2_v.reshape(-1,1),y.reshape(-1,1)\n",
    "    final_x_v=np.concatenate((x1_v,x2_v),axis=1) # Series of independent features\n",
    "    #print(final_x_v)\n",
    "    X_train,X_test,y_train,y_test=final_x_v[:-test_periods],final_x_v[-test_periods:],y[:-test_periods],y[-test_periods:] #Splitting data in train and test\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a80a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated the input data required for forcasting future values using regression models\n",
    "def reg_model_data_generator(data,periods):\n",
    "    sales = data.copy(deep=True)\n",
    "    d = sales.columns[0]\n",
    "    sales['Lag_p']=sales[d].shift(periods) # Lag for p periods\n",
    "    sales['Lag_p1']=sales[d].shift(periods+1) # Lag for p+1 periods\n",
    "    sales=sales.dropna()\n",
    "    x1,x2,y = np.array(sales['Lag_p']),np.array(sales['Lag_p1']),np.array(sales[d])\n",
    "    x1,x2=x1.reshape(-1,1),x2.reshape(-1,1)\n",
    "    x_model,y_model = np.concatenate((x1,x2),axis=1),y\n",
    "    x1_pred,x2_pred = np.array(sales[d][-periods:]),np.array(sales[d][-(periods+1):-1])\n",
    "    x1_pred,x2_pred=x1_pred.reshape(-1,1),x2_pred.reshape(-1,1)\n",
    "    x_pred = np.concatenate((x1_pred,x2_pred), axis=1)\n",
    "    return x_model,y_model,x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aaf4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the metrics (RMSE, MAPE, MAE) of the prediction models\n",
    "def metrics(predictions,targets):\n",
    "    return round(np.sqrt(((predictions - targets) ** 2).mean()),2),round((np.mean(np.abs((targets - predictions)/targets))*100),2), round(mae(targets, predictions),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bcc99",
   "metadata": {},
   "source": [
    "# Functions for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e70fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 week Moving Average\n",
    "def ma12_prediction(sales,periods_of_forecast):\n",
    "    #sales = sales[[d]]\n",
    "    model = ARIMA(sales, order=(0,0,9))\n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(steps=periods_of_forecast)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78b7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto ARIMA\n",
    "def ar_prediction(sales,d,periods_of_forecast):\n",
    "    model_auto = pm.auto_arima(sales[d], start_p=0, d=return_stationary(sales),start_q=0,\n",
    "                          max_p = 5,max_d=2,max_q=5, m = 0, seasonal = False,\n",
    "                          max_order=2,test='adf',error_action = 'ignore',\n",
    "                          suppress_warnings =True,\n",
    "                          stepwise =True,trace = True, n_fits=50)\n",
    "    model_auto_fit = model_auto.fit(sales[d])\n",
    "    predictions = model_auto_fit.predict(n_periods=periods_of_forecast)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1fd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA\n",
    "def sarima_prediction(sales,d,periods_of_forecast):\n",
    "    p = q = range(0, 2)\n",
    "    diff= range(0, 2)\n",
    "    pdq = list(itertools.product(p, diff, q))\n",
    "    ARIMA_AIC = pd.DataFrame(columns=['param', 'AIC'])\n",
    "    for param in pdq:\n",
    "        ARIMA_model = ARIMA(sales[d],order=param).fit()\n",
    "        #print('ARIMA{} - AIC:{}'.format(param,ARIMA_model.aic))\n",
    "        ARIMA_AIC = ARIMA_AIC.append({'param':param, 'AIC': ARIMA_model.aic}, ignore_index=True)\n",
    "    ARIMA_AIC = ARIMA_AIC.sort_values(by='AIC',ascending=True)\n",
    "    model=sm.tsa.statespace.SARIMAX(sales[d],order=(ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][0], ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][1], ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][2]),seasonal_order=(ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][0],ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][1],ARIMA_AIC['param'][ARIMA_AIC['param'].index[0]][2],12))\n",
    "    results=model.fit()\n",
    "    predictions=results.predict(start=sales.count()[0],end=sales.count()[0]+periods_of_forecast-1,dynamic=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60003740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def rf_prediction(X_training,y_training,X_prediction):\n",
    "    model=RandomForestRegressor(n_estimators=100,max_features=2, random_state=1)\n",
    "    #Creating values for model metrics calculation\n",
    "    model.fit(X_training,y_training) # Fitting the model\n",
    "    predictions=model.predict(X_prediction) # Getting predictions for test phase\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199b361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost\n",
    "def xgb_prediction(X_train,y_train,X_test):\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X_train,y_train) # Fitting the model\n",
    "    predictions=model.predict(X_test) # Getting predictions for test phase\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4f687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plots of the predictions and actual values\n",
    "def visualize(data,d,actual_values,prediction_test,prediction_future):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(actual_values)\n",
    "    plt.plot(prediction_test)\n",
    "    plt.legend([\"Actual\",\"Prediction\"], loc =\"lower right\")\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(data[d])\n",
    "    plt.plot(prediction_future)\n",
    "    plt.legend([\"Actual\",\"Prediction\"], loc =\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a650c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of winner model\n",
    "def win(df,models,metric,d):\n",
    "    l=[]\n",
    "    for i in range(len(models)):\n",
    "        l.append(metrics(df[d],df[models[i]])[metric])\n",
    "    min_index=0\n",
    "    for i in range(len(l)):\n",
    "        if l[i]<l[min_index]:\n",
    "            min_index=i\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f007009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display which model is winning\n",
    "def display_winning_model(models,index):\n",
    "    print(f'The winner model is {models[index]} model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e9f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions of average of all models in test period\n",
    "# def average_test(models_without_average):\n",
    "#     test_values = {models_without_average[0]:ar_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),models_without_average[1]:sarima_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),models_without_average[2]:ma12_prediction(train_test_data_prep_ts(data,training_periods)[0],len(train_test_data_prep_ts(data,training_periods)[1])),models_without_average[3]: rf_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1]),models_without_average[4]:xgb_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1])}\n",
    "#     data_test_pred = pd.DataFrame(columns=models_without_average)\n",
    "#     for model in models_without_average:\n",
    "#         data_test_pred[model]=test_values[model]\n",
    "#     data_test_pred['Average']=data_test_pred[models].mean(axis=1)\n",
    "#     return data_test_pred['Average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad64b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing average of all models\n",
    "# def average_model(models_without_average):\n",
    "#     pred_df = pd.DataFrame(columns=models_without_average)\n",
    "#     for model in models_without_average:\n",
    "#         pred_df[model]=prediction_values[model]\n",
    "#     pred_df['Average']=pred_df[models_without_average].mean(axis=1)\n",
    "#     return pred_df['Average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d401a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Dataframe of models and metrics\n",
    "def metrics_table(list_metric,models,d):\n",
    "    metrics_table=pd.DataFrame(columns=models)\n",
    "    for i in models:\n",
    "        metrics_table[i] = list(metrics(data_test_pred[i],train_test_data_prep_ts(data)[1][d]))\n",
    "    metrics_table['Metric']=list_metric\n",
    "    metrics_table = metrics_table.set_index('Metric')\n",
    "    return metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70e2b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10',\n",
       "       ...\n",
       "       'P810', 'P811', 'P812', 'P813', 'P814', 'P815', 'P816', 'P817', 'P818',\n",
       "       'P819'],\n",
       "      dtype='object', length=811)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_multi.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8f5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    testing_periods = int(input('Enter the time periods for testing: ')) #Time period for testing\n",
    "    training_periods = len(sales_multi)-testing_periods #Time period for training\n",
    "    forecast_periods = int(input('Enter the time periods for forecast: ')) #Time period for forecasting future values\n",
    "    user_input_metric = input('Enter the metric: ')\n",
    "    pred_multi = pd.DataFrame(columns=[sales_multi.columns[1:10]])\n",
    "    models = ['ARIMA','SARIMA','Moving Average','Random Forest','XGBoost','Average'] #Change here when add/delete model\n",
    "    models_without_average = ['ARIMA','SARIMA','Moving Average','Random Forest','XGBoost'] #Change here when add/delete model\n",
    "    list_of_metrics=['RMSE','MAE','MAPE'] #Change here when add/delete metric\n",
    "    mapping_dict = {list_of_metrics[0]:0,list_of_metrics[1]:1,list_of_metrics[2]:2}\n",
    "    # Takes the input of metric of choice from the user and stores it\n",
    "    metric_index = mapping_dict[user_input_metric] #storing the index of metrics\n",
    "  \n",
    "       \n",
    "    for d in sales_multi.columns[1:]:\n",
    "        \n",
    "        #d = input('Enter the name of Product: ')\n",
    "        #data = pd.read_csv(f'{d}.csv', index_col='Date', parse_dates=True)\n",
    "        # mapping of models with their predictions in the test period\n",
    "        data = sales_multi[[d]]\n",
    "        test_values = {models[0]:ar_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[1]:sarima_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[2]:ma12_prediction(train_test_data_prep_ts(data,training_periods)[0],len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[3]: rf_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1]),\\\n",
    "                       models[4]:xgb_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1])}\n",
    "        # creating a data frame of predictions of all models including the average model\n",
    "        test_df = train_test_data_prep_ts(data,training_periods)[1]\n",
    "        for i in models_without_average:\n",
    "            test_df[i]=test_values[i]\n",
    "        test_df['Average']=test_df[models_without_average].mean(axis=1)\n",
    "        # mapping of models with their predictions in the future\n",
    "        prediction_values = {models[0]:ar_prediction(data,d,forecast_periods),\\\n",
    "                             models[1]:sarima_prediction(data,d,forecast_periods),\\\n",
    "                             models[2]:ma12_prediction(data,forecast_periods),\\\n",
    "                             models[3]: rf_prediction(reg_model_data_generator(data,forecast_periods)[0],reg_model_data_generator(data,forecast_periods)[1],reg_model_data_generator(data,forecast_periods)[2]),\\\n",
    "                             models[4]:xgb_prediction(reg_model_data_generator(data,forecast_periods)[0],reg_model_data_generator(data,forecast_periods)[1],reg_model_data_generator(data,forecast_periods)[2])}\n",
    "        # Dictionary is created that maps the metric to a numeric value\n",
    "        index_of_winner_model = win(test_df,models,metric_index,d) #storing the index of winner model\n",
    "        display_winning_model(models,index_of_winner_model) #Display the name of winner model\n",
    "        #Creating a Data Frame of predictions of all the models including the average of all models\n",
    "        predict_df = pd.DataFrame(prediction_values[models[0]],columns=[models[0]])\n",
    "        for i in range(1,len(models_without_average)):\n",
    "            predict_df[models_without_average[i]]=prediction_values[models_without_average[i]]\n",
    "        predict_df['Average']=predict_df[models_without_average].mean(axis=1)\n",
    "        # Display predictions and plots\n",
    "        \n",
    "        #display(predict_df)\n",
    "        pred_multi[d] = predict_df[models[index_of_winner_model]]\n",
    "        #visualize(data,d,train_test_data_prep_ts(data,training_periods)[1],test_df[models[index_of_winner_model]],predict_df[models[index_of_winner_model]])\n",
    "    pred_multi.to_csv('Multi_predictions_she3r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0873c256",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     training_periods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnter the time periods for training: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#Time period for training\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     forecast_periods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter the time periods for forecast: \u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m#Time period for testing\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     user_input_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter the metric: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for d in sales_multi.columns[1:]:\n",
    "\n",
    "        # mapping of models with their predictions in the test period\n",
    "        data = sales_multi[[d]]\n",
    "        test_values = {models[0]:ar_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[1]:sarima_prediction(train_test_data_prep_ts(data,training_periods)[0],d,len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[2]:ma12_prediction(train_test_data_prep_ts(data,training_periods)[0],len(train_test_data_prep_ts(data,training_periods)[1])),\\\n",
    "                       models[3]: rf_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1]),\\\n",
    "                       models[4]:xgb_prediction(train_test_data_prep_reg(data,forecast_periods,training_periods)[0],train_test_data_prep_reg(data,forecast_periods,training_periods)[2],train_test_data_prep_reg(data,forecast_periods,training_periods)[1])}\n",
    "        # creating a data frame of predictions of all models including the average model\n",
    "        test_df = train_test_data_prep_ts(data,training_periods)[1]\n",
    "        for i in models_without_average:\n",
    "            test_df[i]=test_values[i]\n",
    "        test_df['Average']=test_df[models_without_average].mean(axis=1)\n",
    "        # mapping of models with their predictions in the future\n",
    "        prediction_values = {models[0]:ar_prediction(data,d,forecast_periods),\\\n",
    "                             models[1]:sarima_prediction(data,d,forecast_periods),\\\n",
    "                             models[2]:ma12_prediction(data,forecast_periods),\\\n",
    "                             models[3]: rf_prediction(reg_model_data_generator(data,forecast_periods)[0],reg_model_data_generator(data,forecast_periods)[1],reg_model_data_generator(data,forecast_periods)[2]),\\\n",
    "                             models[4]:xgb_prediction(reg_model_data_generator(data,forecast_periods)[0],reg_model_data_generator(data,forecast_periods)[1],reg_model_data_generator(data,forecast_periods)[2])}\n",
    "        # Dictionary is created that maps the metric to a numeric value\n",
    "        index_of_winner_model = win(test_df,models,metric_index,d) #storing the index of winner model\n",
    "        display_winning_model(models,index_of_winner_model) #Display the name of winner model\n",
    "        #Creating a Data Frame of predictions of all the models including the average of all models\n",
    "        predict_df = pd.DataFrame(prediction_values[models[0]],columns=[models[0]])\n",
    "        for i in range(1,len(models_without_average)):\n",
    "            predict_df[models_without_average[i]]=prediction_values[models_without_average[i]]\n",
    "        predict_df['Average']=predict_df[models_without_average].mean(axis=1)\n",
    "        # Display predictions and plots\n",
    "        pred_multi[d] = predict_df[models[index_of_winner_model]]\n",
    "        #visualize(data,d,train_test_data_prep_ts(data,training_periods)[1],test_df[models[index_of_winner_model]],predict_df[models[index_of_winner_model]])\n",
    "    pred_multi.to_csv('Multi_predictions_she3r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce76a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
